{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLiP Support-Vector-Machine (SVM) am Beispiel Rattern\n",
    "Kurs Maschinelles Lernen in der Produktion\n",
    "\n",
    "#### In diesem Notebook wird das Verfahren Support-Vector-Machine (SVM) anhand des Anwendungsbeispiels Rattern geübt. \n",
    "\n",
    "Bei der Fertigung von Bauteilen treten manchmal störende Schwingungen auf, sog. Rattern. Dieses schädigt die Werkzeuge und führt zu einer niedrigeren Bauteilqualität.\n",
    "\n",
    "Im Datensatz \"Rattern\" werden die Drehzahl der Spindel und die Tiefe des Schnitts einer CNC-Fräse gemessen. Es soll eine Support-Vector-Machine (SVM) erstellt werden welche vorhersagen kann bei welcher Kombination aus Drehzahl und Tiefe das sog. Rattern auftritt. \n",
    "### Data-Mining-Prozess:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bild konnte nicht geladen werden! 1. Daten erfassen - 2. Daten erkunden - 3. Daten vorbereiten - 4. Modelle bilden - 5. Modelle validieren - 6. Modell testen](Prozess_Modellentwicklung_v2.png \"ML Vorgehen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#Einstellungen für die Grafikausgabe\n",
    "style = 'seaborn-whitegrid'\n",
    "plt.style.use(style)\n",
    "plt.rcParams.update({'font.size': 14})  # Schriftgröße aller Textzeichen im Graphen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Wähle eine Zahl zwischen 1 und 100 für die Generierung deiner spezifischen Zufallszahlen my_seed=\n",
    "\n",
    "(Wähle für alle Notebooks in allen Übungen immer die gleiche Zahl (z.B. den Tag deines Geburtstags), dann sind die Ergebnisse der verschiedenen Machine-Learning-Verfahren vergleichbar da dann alle Notebooks mit der \"gleichen\" Folge an Zufallszahlen arbeiten)\n",
    "\n",
    "AUSGABE:\n",
    "* Gewählte Zufallszahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Ausgabe gewählte Zufallszahlen\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Daten erfassen - Daten importieren\n",
    "\n",
    "Import der Daten mittels der read_csv-Funktion von Pandas.  \n",
    "Achtung, es gibt zwei Datensätze, einen mit den Trainingsdaten und einen mit den Testdaten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade Datensatz\n",
    "df_train = pd.read_csv(\"Trainingsdaten_Rattern.csv\")\n",
    "df_test = pd.read_csv(\"Testdaten_Rattern.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Daten erkunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz anzeigen\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz beschreiben\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeige Klassenzugehörigkeit an\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "surf = plt.scatter(df_train[\"Drehzahl Spindel\"],\n",
    "                   df_train[\"Tiefe des Schnitts\"],\n",
    "                   c=df_train[\"Rattern\"],\n",
    "                   cmap=plt.cm.coolwarm,\n",
    "                   s=150,\n",
    "                   alpha=0.7,\n",
    "                   edgecolors=\"black\")\n",
    "plt.colorbar(surf)\n",
    "plt.xlim(7750, 16250)\n",
    "plt.ylim(0, 0.023)\n",
    "plt.xlabel(\"Drehzahl Spindel\")\n",
    "plt.ylabel(\"Tiefe des Schnitts\")\n",
    "plt.title(\"Effekt des Ratterns über Schnitttiefe und Spindeldrehzahl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Daten vorbereiten - Aufteilen in Features und Label\n",
    "\n",
    "Die Trainingsdaten und Testdaten wurden getrennt importiert, die Validierungsdaten werden mittels Cross-Validation aus den Trainingsdaten gewählt. Somit müssen wir nur noch die Aufteilung in X und y vornehmen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Teile Datensatz in X und y auf\n",
    "X_train_ = df_train[[\"Drehzahl Spindel\", \"Tiefe des Schnitts\"]]\n",
    "y_train = df_train[\"Rattern\"]\n",
    "\n",
    "X_test_ = df_test[[\"Drehzahl Spindel\", \"Tiefe des Schnitts\"]]\n",
    "y_test = df_test[\"Rattern\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Daten vorbereiten - Normierung der Daten\n",
    "__Optional__ können die Input-Parameter (Schnitttiefe und Spindeldrehzahl) normiert werden.   \n",
    "Es stehen grundsätzlich der StandardScaler, der MinMaxScaler und der MaxAbsScaler zur Verfügung. Für dieses Beispiel wurde der StandardScaler vorbereitet.\n",
    "\n",
    "TODO: (Optional, wenn die Daten normiert werden sollen)\n",
    "- Importiere einen Scaler, also entferne das erste Zeichen (#) in Zeilen 7 un 8\n",
    "- Führe die Skalierung für die Trainingsdaten durch, also entferne das erste Zeichen (#) in Zeilen 9\n",
    "- Führe die Skalierung für die Trainingsdaten durch, also entferne das erste Zeichen (#) in Zeilen 10\n",
    "\n",
    "AUSGABE:\n",
    "- Größe der Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normiere Input-Parameter (optionales TODO)\n",
    "# hier passiert keine Normierung\n",
    "X_train = X_train_.copy(deep=True) \n",
    "X_test = X_test_.copy(deep=True)\n",
    "\n",
    "# Durchführung der Normierung:\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler() \n",
    "# X_train = pd.DataFrame(scaler.fit_transform(X_train.values), index=X_train.index, columns=X_train.columns)\n",
    "# X_test = pd.DataFrame(scaler.transform(X_test.values), index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "# Ausgabe Datensätze und Anzahl Datenpunkte\n",
    "print(\"\\nAnzahl Traingsdaten: \\t\" + str(len(y_train)) + \" / \" + str(len(df_train)+len(df_test)))\n",
    "print(\"Anzahl Testdaten: \\t\" + str(len(y_test)) + \" / \" + str(len(df_train)+len(df_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modell bilden - Modell importieren\n",
    "Zuerst müssen wir das SVM Modell importieren, damit wir es später nutzen können. \n",
    "\n",
    "TODO:\n",
    "- Schreibe den Code, um das Modell aus der Bibliothek zu importieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere das Modell aus der Bibliothek sklearn\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschreibung der Hyperparameter:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modelle bilden - Hyperparameter Tuning mittels Gittersuche\n",
    "\n",
    "Für die __SVM mit rbf-Kernel__ werden in diesem Notebook __4 Hyperparameter__ eingestellt:\n",
    "- kernel: Der Kernel.\n",
    "- C: Der Strafterm C.\n",
    "- gamma: Der Kernel Koeffizient gamma.\n",
    "- random_state: Die Zufallszahlen zur Erzeugung des Modells.\n",
    "\n",
    "Um die optimalen Werte für die Hyperparameter C und gamma zu finden wird eine __Gittersuche__ durchgeführt:\n",
    "- Bestimme zu probierende Werte für C, gamma\n",
    "- Für diese Werte wird für alle Kombinationen:\n",
    "    - Ein Modell erstellt \n",
    "    - Ein Modell trainiert\n",
    "    - Die Genauigkeit auf den Validationsdaten berechnet\n",
    "- Die Hyperparameter mit der höchsten Genauigkeit werden für das Vorzugsmodell verwendet\n",
    "\n",
    "TODO:\n",
    "- Schreibe die C-Werte für die Gittersuche in eine Liste hinter 'C': (Zeile 7)\n",
    "- Schreibe die gamma-Werte für die Gittersuche in eine Liste hinter 'gamma': (Zeile 7)\n",
    "- Es gibt 3 Möglichkeiten die Werte einzutragen:\n",
    "    - Möglichkeit 1: Manuelles Eintragen in eine Liste: Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    - Möglichkeit 2: Erzeugen einer Liste mit np.linspace(): Cs = np.linspace(von, bis, Anzahl an Werten), z.B. np.linspace(0.1,100, 4)\n",
    "    - Möglichkeit 3: Erzeugen einer Liste mit np.logspace(): Cs = np.logspace(exp. von, exp. bis, Anzahl an Werten) z.B. np.logspace(-5,3,9)\n",
    "\n",
    "- __Optional__, füge den Parameter n_jobs=3 hinzu, damit die GridSearch parallel gerechnet wird.\n",
    "\n",
    "AUSGABE:\n",
    "- Anzahl der getesteten Hyperparameterkombinationen\n",
    "- Zeitdauer für Gittersuche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Werte für die Gittersuche/Hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "start_timer = time.monotonic()\n",
    "hyper_parameters = {\"kernel\": [\"rbf\"], \n",
    "                    \"C\": TODO, \n",
    "                    \"gamma\": TODO, \n",
    "                    \"random_state\": [my_seed]}\n",
    "\n",
    "# Gittersuche: Berechne Genauigkeit auf Validationsdaten für alle möglichen Kombinationen\n",
    "model = SVC()\n",
    "gridSearch = GridSearchCV(model, hyper_parameters, return_train_score=True, cv=5)\n",
    "gridSearch = gridSearch.fit(X_train, y_train)\n",
    "print(\"\\nDie Gittersuche (\"\n",
    "    + str(len(pd.DataFrame(gridSearch.cv_results_)))\n",
    "    + \" Kombinationen) hat \"\n",
    "    + str(\"%.1f\" % (time.monotonic() - start_timer))\n",
    "    + \" Sekunden gedauert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Modelle validieren - GridSearch Ergebnisse begutachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Variablen GridSearch sind nun die Ergebnisse der Gittersuche gespeichert.  \n",
    "\n",
    "Mit dem Befahl GridSearch.cv_results_ bekommen wir die Ergebnis-Tabelle der Gittersuche (hier: besten 5 Ergebnisse):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Ergebnisse\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.DataFrame(gridSearch.cv_results_).sort_values(\"mean_test_score\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bonus:__  \n",
    "Anzeigen einer sog. Heatmap der Hyperparameter C und gamma (nur bei 2 variierenden Hyperparametern möglich):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung des Einflusses der Hyperparameter\n",
    "results = pd.DataFrame(gridSearch.cv_results_)\n",
    "xx = results[\"param_C\"].unique()\n",
    "yy = results[\"param_gamma\"].unique()\n",
    "zz = np.asarray(results[\"mean_test_score\"]).reshape(len(xx), len(yy)).T\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\"GITTERSUCHE: Genauigkeit (Validationsdaten) über den Hyperparametern C und gamma\")\n",
    "surf = plt.contourf(xx, yy, zz, cmap=plt.cm.coolwarm_r)\n",
    "fig.colorbar(surf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Modelle validieren - Modell auswählen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem Befehl GridSearch.best_params_ bekommen wir die besten Hyperparameter der Gittersuche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beste Kombination der Hyperparameter\n",
    "gridSearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun muss das Modell mit den optimalen Hyperparametern erstellt und dann mit den Trainingsdaten trainiert werden.  \n",
    "Diese Aufgabe übernimmt bereits die GridSearch-Funktion. Somit muss das beste Modell nur noch extrahiert werden, das geht mit dem Befehl GridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraktion des Modells\n",
    "model = gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Modelle validieren - Bewertung des Trainings\n",
    "Wir berechnen die Genauigkeit des Modells auf den Trainingsdaten (richtige Vorhersagen/alle Vorhersagen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Vorhersage basierend auf den Trainingsdaten\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Berechne Genauigkeit auf den Trainingsdaten\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Berechne den F1-Score auf den Trainingsdaten\n",
    "f1score_train = f1_score(y_train, y_train_pred)\n",
    "\n",
    "# Ausgabe der Modellgenauigkeit\n",
    "print('Ergebnis für das Training:')\n",
    "print('Accuracy: \\t' + str(round(accuracy_train, 3)))\n",
    "print('F1-Score: \\t' + str(round(f1score_train, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Modell testen & anwenden - Genauigkeit auf Testdaten und Konfusionsmatrix\n",
    "\n",
    "Um die Qualität/Güte des Modells zu bestimmen wird dieses auf den Testdaten getestet und die Konfusionsmatrix ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Vorhersage basierend auf den Testdaten\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Berechne Genauigkeit auf den Testdaten\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Berechne den F1-Score auf den Testdaten\n",
    "f1score_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Ausgabe der Modellgenauigkeit\n",
    "print('Ergebnis für den Test:')\n",
    "print('Accuracy: \\t' + str(round(accuracy_test, 3)))\n",
    "print('F1-Score: \\t' + str(round(f1score_test, 3)))\n",
    "\n",
    "\n",
    "# Visualisierung der Konfusionsmatrix\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
    "plt.grid()\n",
    "plt.title('Konfusionsmatrix auf Testdaten')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Modell testen & anwenden - Modell visualisieren\n",
    "\n",
    "Da das Modell nur 2 Input-Parameter benötigt können wir alle möglichen Modell-Vorhersagen grafisch visualisieren.\n",
    "\n",
    "AUSGABE:\n",
    "- Grafische Visualisierung der Modellvorhersage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Grid für Modellausgabe\n",
    "x = np.linspace(X_train[\"Drehzahl Spindel\"].min(), X_train[\"Drehzahl Spindel\"].max(), 200)\n",
    "y = np.linspace(X_train[\"Tiefe des Schnitts\"].min(), X_train[\"Tiefe des Schnitts\"].max(), 200)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Berechne Modellvorhersage\n",
    "z = pd.DataFrame({\"Drehzahl Spindel\": X.ravel(), \"Tiefe des Schnitts\": Y.ravel()})\n",
    "z = model.predict(z)\n",
    "\n",
    "# Ausgabe Modellvorhersage\n",
    "Z = np.asarray(z).reshape(200, 200)\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "plt.title(\"Modellvorhersage und Datensätze (Train = Kreis, Test = Raute)\")\n",
    "plt.xlabel(\"Drehzahl Spindel\")\n",
    "plt.ylabel(\"Tiefe des Schnitts\")\n",
    "surf = plt.contourf(X, Y, Z, cmap=plt.cm.coolwarm)\n",
    "plt.colorbar(surf)\n",
    "plt.scatter(X_train[\"Drehzahl Spindel\"],\n",
    "            X_train[\"Tiefe des Schnitts\"],\n",
    "            c=y_train,\n",
    "            marker=\"o\",\n",
    "            alpha=0.3,\n",
    "            edgecolors=\"black\",\n",
    "            s=70)\n",
    "plt.scatter(X_test[\"Drehzahl Spindel\"],        \n",
    "            X_test[\"Tiefe des Schnitts\"],\n",
    "            c=y_test,\n",
    "            marker=\"D\",\n",
    "            edgecolors=\"black\",\n",
    "            s=70)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MLiP)",
   "language": "python",
   "name": "python-mlip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
