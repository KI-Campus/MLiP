{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLiP Regression & Gradientenverfahren\n",
    "Kurs Maschinelles Lernen in der Produktion\n",
    "\n",
    "#### In diesem Notebook soll das Gradientenverfahren am Beispiel der Linearen Regression veranschaulicht werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere benötigte Bibliotheken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "style = 'seaborn-whitegrid'\n",
    "plt.style.use(style)\n",
    "plt.rcParams.update({'font.size': 14})  # Schriftgröße aller Textzeichen im Graphen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Daten erfassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere Datensatz\n",
    "df = pd.read_excel('Daten - Gradientenverfahren.xlsx')\n",
    "print('Daten erfolgreich eingelesen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Daten erkunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe Graph\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['X'], df['Y'], 'o') \n",
    "plt.xlabel('X-Wert')\n",
    "plt.ylabel('Y-Wert')\n",
    "plt.title('Datensatz')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setze Start-Gerade und wähle Lernrate\n",
    "\n",
    "TODO: \n",
    "- Stell die Lernrate für die Regression ein (Werte zwischen 0 und 1, z.B. 0.02)\n",
    "\n",
    "AUSGABE:\n",
    "- Graph: Daten und Start-Regressionsgerade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lernrate\n",
    "learning_rate = TODO\n",
    "\n",
    "# Setze zufällige Regressionsgerade\n",
    "w_0 = 2.0\n",
    "w_1 = 1.0\n",
    "\n",
    "# Zähler für Iterationsschritte\n",
    "iteration = 0\n",
    "\n",
    "# Vorhersage basieren auf Startwerte\n",
    "df['Y_pred'] =  w_0 + df['X'] * w_1\n",
    "\n",
    "# Leerer Dataframe für spätere Ergebnisse\n",
    "results = pd.DataFrame(columns=['Schritt', 'Abweichung', 'Regressionsgerade']); \n",
    "\n",
    "# Ausgabe Graph\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df['X'], df['Y'], 'o', df['X'], df['Y_pred'], '-o')\n",
    "plt.xlabel('X-Wert')\n",
    "plt.ylabel('Y-Wert')\n",
    "plt.title('Datensatz mit Startgerade')\n",
    "plt.legend(['Daten', 'Regressionsgerade'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Schrittweise Optimierung der Geraden (Gradientenverfahren)\n",
    "\n",
    "TODO:\n",
    "- Mehrmaliges Ausführen des Code-Blocks \n",
    "- Zum Einstellen einer neuen Lernrate ändere diese im 2. Code-Block und führe diesen 1x aus, das setzt sowohl die Tabelle sowie die Graphen zurück\n",
    "\n",
    "AUSGABE:\n",
    "- Tabelle mit Schrittanzahl, RMSE und Regressiongeraden\n",
    "- Graph aller Regressionsgeraden\n",
    "\n",
    "Nach jedem Ausführen wird die Tabelle sowie der Graph erweitert (aktuelle Gerade und Fehler), hier können Sie sowohl visuell als auch anhand des RMSE den Verlauf betrachten. Führe die Schrittweise Regression für verschiedene Lernraten beginne mit 0,02) durch und bewerte die jeweilige Lernrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Schrittweise Regression\n",
    "\n",
    "# Erzeuge Variablennamen\n",
    "Y_pred_name = \"Y_pred_\" + str(iteration)\n",
    "Y_r_name = \"Y_r_\" + str(iteration)\n",
    "\n",
    "# Berechne aktuelle Vorhersage und Abweichung zum echten Wert\n",
    "df[Y_pred_name] = w_0 + df['X'] * w_1\n",
    "df[Y_r_name] = df['Y'] - df[Y_pred_name]\n",
    "\n",
    "# Erstelle Tabelle mit Schritt, Fehler und Regressionsgerade\n",
    "DS_3 = pd.DataFrame({'Schritt': [iteration], 'Abweichung': [(((df[Y_r_name])**2).mean())**(1.0/2.0)], 'Regressionsgerade': [str('y = ' + str(\"%.2f\" % w_0) + ' + ' + str(\"%.2f\" % w_1) + ' * x')]})\n",
    "results = results.append(DS_3)\n",
    "\n",
    "# Berechne Gradienten\n",
    "gradient_w0 = -df[Y_r_name].mean() * 2\n",
    "gradient_w1 = (-df['X'] * df[Y_r_name]).mean() * 2 \n",
    "\n",
    "# Berechne neue Parameter der Regressionsgeraden\n",
    "w_0 = w_0 - learning_rate * gradient_w0\n",
    "w_1 = w_1 - learning_rate * gradient_w1\n",
    "\n",
    "# Berechnung von Koordinaten für Plot\n",
    "R_X_1, R_X_2, R_X_3, R_X_4, R_X_5 = [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]\n",
    "R_Y_1 = [df['Y'][0],df[Y_pred_name][0]]\n",
    "R_Y_2 = [df['Y'][1],df[Y_pred_name][1]]\n",
    "R_Y_3 = [df['Y'][2],df[Y_pred_name][2]]\n",
    "R_Y_4 = [df['Y'][3],df[Y_pred_name][3]]\n",
    "R_Y_5 = [df['Y'][4],df[Y_pred_name][4]]\n",
    "\n",
    "# Ausgabe Tabelle\n",
    "print(\"\\n\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "\n",
    "# Ausgabe Graph\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(df['X'], df['Y'], marker='o', markersize=12, linewidth=0)\n",
    "plt.plot(df['X'], df[Y_pred_name], marker='o', markersize=12, linewidth=4)\n",
    "plt.plot(R_X_1, R_Y_1, 'k--', R_X_2, R_Y_2, 'k--', R_X_3, R_Y_3, 'k--', R_X_4, R_Y_4, 'k--', R_X_5, R_Y_5, 'k--')\n",
    "for i in range(iteration):\n",
    "    Y_pred_name = \"Y_pred_\" + str(i)\n",
    "    X = [1,5]\n",
    "    Y = [df[Y_pred_name][0], df[Y_pred_name][4]]\n",
    "    plt.plot(X, Y, 'k-', alpha=0.3)     \n",
    "    \n",
    "plt.xlabel('X-Wert')\n",
    "plt.ylabel('Y-Wert')\n",
    "plt.title('Schrittweise lineare Regression')\n",
    "plt.xlim(0.5, 5.5)\n",
    "plt.legend(['Datensatz', 'aktuelle Regressionsgerade', 'Abweichung: Gerade - Reale Daten'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Iterationsschritte mitzählen\n",
    "iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualisierung der Fehlerfläche und deren Minimierung (Gradientenverfahren)\n",
    "\n",
    "TODO:\n",
    "- Stelle nacheinander die Lernraten (0.08, 0.03, 0.01, 0.001, 0.084) ein \n",
    "- Stelle die Anzahl der durchzuführenden Schritte ein (mindestens 10 & maximal 1000) \n",
    "\n",
    "AUSGABE:\n",
    "- RMSE-Werte für Begin, Mitte und Ende\n",
    "- Graph aller Koeffizienten über der Fehlerfläche (RMSE)\n",
    "\n",
    "HINWEIS:\n",
    "- Mitunter muss der Code-Block zweimal ausgeführt werden, damit die Grafik korrekt angezeigt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Code-Block\n",
    "\n",
    "# Lernrate und Schritte\n",
    "learning_rate = TODO\n",
    "iterations = TODO\n",
    "\n",
    "# Startgerade\n",
    "w_0s = [2]\n",
    "w_1s =  [1]\n",
    "rmses = []\n",
    "x0 = []\n",
    "x1 = []\n",
    "y0 = [] \n",
    "y1 = [] \n",
    "z = []\n",
    "df_2 = df.copy()\n",
    "\n",
    "# Berechne Geraden für Iterations\n",
    "for nr_iteration in range(iterations):\n",
    "    # Speichere Fehler\n",
    "    df_2['Y_diff'] = df_2['Y'] - (df_2['X'] * w_1s[-1] + w_0s[-1])\n",
    "    rmses.append((((df_2['Y_diff'])**2).mean()) ** (1.0/2.0))\n",
    "    # Speichere Gerade\n",
    "    x0.append(1); x1.append(5)\n",
    "    y0.append(1 * w_1s[-1] + w_0s[-1])\n",
    "    y1.append(5 * w_1s[-1] + w_0s[-1])\n",
    "    # Berechne neue Koeffizienten\n",
    "    gradient_w0 = -df_2['Y_diff'].mean() * 2\n",
    "    gradient_w1 = (-df_2['Y_diff'] * df_2['X']).mean() * 2 \n",
    "    w_0s.append(w_0s[-1] - learning_rate * gradient_w0)\n",
    "    w_1s.append(w_1s[-1] - learning_rate * gradient_w1)\n",
    "    \n",
    "# Berechne Fehlerfläche \n",
    "# Berechne Grenzen\n",
    "w0_max  = max(w_0s)\n",
    "w0_min = min(w_0s)\n",
    "w0_dif = (max(w_0s)-min(w_0s)) * 0.2\n",
    "w1_max = max(w_1s)\n",
    "w1_min = min(w_1s)\n",
    "w1_dif = (max(w_1s)-min(w_1s)) * 0.2\n",
    "\n",
    "# Berechne Grid für Plot\n",
    "w0_L = np.linspace(min(-1.0, w0_min) - w0_dif, max(1.0, w0_max) + w0_dif, 50)\n",
    "w1_L = np.linspace(min(1.0,w1_min) - w1_dif, max(1.5, w1_max) + w1_dif, 50)\n",
    "X,Y = np.meshgrid(w0_L, w1_L)\n",
    "\n",
    "# Berechne Fehler je Gridpunkt\n",
    "for point in range(50*50):\n",
    "    df_2['Y_diff'] = df_2['Y'] - (df_2['X'] * Y.ravel()[point] + X.ravel()[point])\n",
    "    z.append((((df_2['Y_diff'])**2).mean()) ** (1.0/2.0))\n",
    "Z = np.asarray(z).reshape(50, 50)\n",
    "\n",
    "# Ausgabe\n",
    "print('\\nKostenfunktion (Start):\\t' + str(\"%.5f\" % rmses[0]) + '\\nKostenfunktion (Ende): \\t' + str(\"%.5f\" % rmses[nr_iteration-1]))\n",
    "\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "c = np.linspace(0, 1, len(rmses))\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plt.title(\"Fehlerfläche (Kostenfunktion) über w_0 & w_1\")\n",
    "plt.xlabel('w_0')\n",
    "plt.ylabel('w_1')\n",
    "ax.scatter(w_0s[:-1], w_1s[:-1], 0, '-o', s=40, color = '0.75')\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.viridis, alpha=0.5, antialiased=False, rstride=3, cstride=3)\n",
    "ax.plot(w_0s[:-1], w_1s[:-1], rmses, 'k-o', markersize=7)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5) \n",
    "\n",
    "# Winkel für Ansicht (Höhenwinkel, Seitenwinkel)\n",
    "ax.view_init(30, 150)\n",
    "ax.view_init(0, 220)\n",
    "plt.show()\n",
    "\n",
    "print('Gewichte (Ende):')\n",
    "print('w_0: ' + str(w_0s[-1]))\n",
    "print('w_1: ' + str(w_1s[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Lineare Regression automatisch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "# Daten vorbereiten\n",
    "X = df[['X']]\n",
    "y = df[['Y']]\n",
    "\n",
    "# Modell bilden\n",
    "# Erstellen des Modells\n",
    "linear_mdl = LinearRegression()\n",
    "#Trainieren des Modells\n",
    "linear_mdl = linear_mdl.fit(X, y)\n",
    "\n",
    "# Berechne Regressionsgerade für Plot\n",
    "X_grid = pd.DataFrame({'X' : np.linspace(1, 5, 100)})\n",
    "y_grid = linear_mdl.predict(X_grid)\n",
    "\n",
    "# Ausgabe Graph\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df['X'], df['Y'], 'o')\n",
    "plt.plot(X_grid, y_grid, linewidth=2.5) \n",
    "plt.plot(X_grid, w_0s[-1] + w_1s[-1] * X_grid,'k', alpha=0.5)\n",
    "plt.xlabel('X-Wert')\n",
    "plt.ylabel('Y-Wert')\n",
    "plt.title('Datensatz mit Startgerade')\n",
    "plt.legend(['Daten', 'Regressionsgerade', 'automatische Regressionsgerade'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnis der implementierten Linearen Regression\n",
    "print('w_0: ' + str(linear_mdl.intercept_[0]))\n",
    "print('w_1: ' + str(linear_mdl.coef_[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
