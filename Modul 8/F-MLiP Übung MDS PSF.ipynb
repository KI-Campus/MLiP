{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLiP MDS am Beispiel PSF\n",
    "Kurs Maschinelles Lernen in der Produktion\n",
    "\n",
    "#### In diesem Notebook wird das MDS anhand des Anwendungsbeispiels Profilschienenführung (PSF) geübt. \n",
    "\n",
    "Linearführungen und Profilschienenführungen sind für einen nicht unbedeutenden Teil der Ausfälle bei Werkzeugmaschinen.\n",
    "Typische Fehlerfälle die dabei auftreten sind Mangelschmierungen, Pittings an Laufbahnen oder an den Wälzkörpern. In diesem Beispiel ist aber der grundlegende Zustand der PSF von Interesse, d.h. ist der Zustand fehlerfrei (OK) oder machen sich Verschleißerscheinungen (Ausfall) deutlich. \n",
    "\n",
    "Für dieses Beispiel wurden mehrere Profilschienen unter Belastung bis zu ihrem Lebensende verfahren. Die dabei auftretenden Fehler sind natürlich entstanden. Dementsprechend unterscheiden Sie sich sowohl in der Art als auch in der Stärke. \n",
    "\n",
    "Während der Versuche wurde mittels einem 3-achsigen MEMS-Sensor die Beschleunigungen, in Verfahrrichtung (Acc_X)\n",
    "in Richtung oder entgegen Erdmittelpunkt (Acc_Y) und orthogonal zu beiden in Richtung des Seitennormalenvektor des Versuchsstands (Acc_Z) aufgenommen. Die entsprechenden Zeitreihen:\n",
    "<table><tr>\n",
    "<td> <img src=\"MLiP_PSF_Messfahrt_gut.png\" alt=\"Status OK\" style=\"width: 350px;\"/> </td>\n",
    "<td> <img src=\"MLiP_PSF_Messfahrt_ausfall.png\" alt=\"Status Ausfall\" style=\"width: 350px;\"/> </td>\n",
    "</tr></table>\n",
    "Für diese Aufgabe wurde nur die Beschleunigung in Verfahrrichtung (Acc_X) verwendet. Deren Werte wurden bereits zu Features zusammengefasst. Ziel ist es nun diese Features mit Hilfe des MDS auf so wenige Dimensionen wie möglich zu reduzieren. \n",
    "\n",
    "\n",
    "### Data-Mining-Prozess:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bild konnte nicht geladen werden! 1. Daten erfassen - 2. Daten erkunden - 3. Daten vorbereiten - 4. Modelle bilden - 5. Modelle validieren - 6. Modell testen](Prozess_Modellentwicklung_v2.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "#Einstellungen für die Grafikausgabe\n",
    "style = 'seaborn-whitegrid'\n",
    "plt.style.use(style)\n",
    "plt.rcParams.update({'font.size': 14})  # Schriftgröße aller Textzeichen im Graphen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Wähle eine Zahl zwischen 1 und 100 für die Generierung deiner spezifischen Zufallszahlen my_seed=\n",
    "\n",
    "(Wähle für alle Notebooks in allen Übungen immer die gleiche Zahl (z.B. den Tag deines Geburtstags), dann sind die Ergebnisse der verschiedenen Machine-Learning-Verfahren vergleichbar da dann alle Notebooks mit der \"gleichen\" Folge an Zufallszahlen arbeiten)\n",
    "\n",
    "AUSGABE:\n",
    "* Gewählte Zufallszahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Ausgabe gewählte Zufallszahlen\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Daten erfassen - Daten importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade Datensatz\n",
    "df = pd.read_csv(\"CM_PSF_Features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Daten erkunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz anzeigen\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Daten vorbereiten - Auswahl der Daten\n",
    "Es werden 6 Prüflinge aus dem Datensatz ausgewählt. Die MDS für den Gesamtdatensatz dauert die Berechnung zu lange. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen der Daten in X y\n",
    "selected_df = df[df.Pruefling_ID.isin([107, 108, 109, 126, 127, 128])]\n",
    "selected_df = selected_df.assign(uID = df.Pruefling_ID *10000 + df.Messfahrt_ID ).reset_index(drop=True)\n",
    "X_train = selected_df.drop(columns=['Status', 'Messfahrt_ID', 'Pruefling_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Daten vorbereiten - Daten normieren\n",
    " Für dieses Beispiel wurde der MinMaxScaler vorbereitet.\n",
    "\n",
    "Es können auch andere Scaler verwendet werden, die müssen entsprechend importiert werden und der Befehl scaler = ... muss angepasst werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max-Skalierung der Daten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train.values), index=X_train.index, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modell bilden - Modell Importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren des Modells\n",
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschreibung der Hyperparameter:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.manifold.MDS.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modelle bilden - Distanzmetriken berechnen\n",
    "Dieser Schritt ist eigentlich nur notwendig, wenn nicht die euklidische Metrik als Abstandsmaß gewünscht ist. \n",
    "\n",
    "__[OPTIONAL]__ Nur nötig wenn für 'dissimilarity' nicht 'euclidean' gewählt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL] Nur nötig wenn für 'dissimilarity' nicht 'euclidean' gewählt wird.\n",
    "\n",
    "# Erstelle eigenes Maß für Verschiedenheit\n",
    "from sklearn.metrics import pairwise as metr\n",
    "\n",
    "euclidean_similarities = metr.euclidean_distances(X_train)\n",
    "cosine_similarities = metr.cosine_distances(X_train)\n",
    "manhatten_similarities = metr.manhattan_distances(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausage der Distanzmetrik für die Abstände bei der euklidischen Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darstellung der euklidischen Abstände als DataFrame\n",
    "pd.DataFrame(euclidean_similarities, index=selected_df.uID, columns=selected_df.uID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modelle bilden - Modell trainieren\n",
    "In diesem Schritt erfolgt die Durchführung der MDS. \n",
    "\n",
    "TODO:\n",
    "* Bestimme die Anzahl der Dimensionen, n_components, auf die skaliert werden soll. \n",
    "\n",
    "Notiz:\n",
    "* Falls 'dissimilarity' = 'euclidean': fit_transform mit X_train\n",
    "* Falls 'dissimilarity' = 'precomputed': fit_transform mit [euclidean_similarities, manhatten_similarities, cosine_similarities] \n",
    "\n",
    "Ausgabe: \n",
    "* Dauer der Berechnung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell erstellen\n",
    "model = MDS(dissimilarity=\"euclidean\",\n",
    "            n_components=TODO,\n",
    "            random_state=my_seed,\n",
    "            n_jobs=-2)\n",
    "\n",
    "# Variante für andere Metriken\n",
    "#model = MDS(dissimilarity=\"precomputed\",\n",
    "#            n_components=TODO,\n",
    "#            random_state=my_seed,\n",
    "#            n_jobs=-2)\n",
    "\n",
    "# Scalierung durchführen\n",
    "start_timer = time.monotonic()\n",
    "X_train_trans = model.fit_transform(X_train)\n",
    "\n",
    "# Variante für andere Metriken, hier z.B. für manhatten_similarities\n",
    "# X_train_trans = model.fit_transform(manhatten_similarities)\n",
    "\n",
    "print(\"\\nDauer \" + str(\"%.1f\" % (time.monotonic() - start_timer))\n",
    "      + \" Sekunden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Modelle validieren - Visuelle Bewertung\n",
    "\n",
    "Um die Qualität/Güte des Modells zu bestimmen, wird diese visuell überprüft.\n",
    "\n",
    "<font color='red'>Die Visualisierungen funktionieren nur bei Modellen mit n_components = 2 oder 3!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuelle Darstellung für Transformation auf 2 bzw. 3 Komponenten\n",
    "X_transformed = np.transpose(X_train_trans)\n",
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "mycolors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "y_colors = [mycolors[status] for status in encoder.fit_transform(selected_df[\"Status\"])]\n",
    "if len(X_transformed) == 2:\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    plt.scatter(X_transformed[0], X_transformed[1],\n",
    "                s=200,        \n",
    "                alpha=0.5,\n",
    "                c=y_colors,\n",
    "                edgecolors=\"black\",\n",
    "                marker=\"o\")\n",
    "    plt.title(\"Visualisierung: Multidimensional-Scaling auf 2 Input-Parameter\")\n",
    "    plt.show()\n",
    "    \n",
    "elif len(X_transformed)== 3:\n",
    "    # 3D-Plot Ergebnis Clustering\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    from matplotlib.patches import Patch\n",
    "    \n",
    "    # 3D Plot-Befehl\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    legend = []\n",
    "\n",
    "    # Plot der Datenpunkte mit Einfärbung\n",
    "    ax.scatter(X_transformed[0], X_transformed[1], X_transformed[2],\n",
    "               c=y_colors,\n",
    "               marker=\"o\",\n",
    "               s=140)\n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.set_zlabel(\"x3\")\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(str(len(X_transformed))\n",
    "        + \" statt 2 oder 3 Komponenten, für eine grafische Darstellung ein Modell mit n_components = 2 oder 3 trainieren.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Komplexere Visualisierung mit unterschiedlichen Markern je Prüfling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuelle Darstellung für Transformation auf 2 bzw. 3 Komponenten\n",
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(selected_df[\"Status\"])\n",
    "mycolors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "markers = ['.', 'o', 'v', 's', 'P', '*']\n",
    "if len(X_transformed) == 2:\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    for idx, Pruefling_ID in enumerate(selected_df.Pruefling_ID.unique()):\n",
    "        plt.scatter(X_train_trans[selected_df.Pruefling_ID==Pruefling_ID, 0], X_train_trans[selected_df.Pruefling_ID==Pruefling_ID,1],\n",
    "                    s=200,        \n",
    "                    alpha=0.5,\n",
    "                    c=[mycolors[status] for status in encoder.transform(selected_df.loc[selected_df.Pruefling_ID==Pruefling_ID,\"Status\"])],\n",
    "                    edgecolors=\"black\",\n",
    "                    marker=markers[idx],\n",
    "                    label=Pruefling_ID)\n",
    "    plt.title(\"Visualisierung: Multidimensional-Scaling auf 2 Input-Parameter\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "elif len(X_transformed)== 3:\n",
    "    # 3D-Plot Ergebnis Clustering\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    from matplotlib.patches import Patch\n",
    "    \n",
    "    # 3D Plot-Befehl\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    \n",
    "    for idx, Pruefling_ID in enumerate(selected_df.Pruefling_ID.unique()):\n",
    "\n",
    "    # Plot der Datenpunkte mit Einfärbung\n",
    "        ax.scatter(X_train_trans[selected_df.Pruefling_ID==Pruefling_ID, 0], \n",
    "                   X_train_trans[selected_df.Pruefling_ID==Pruefling_ID, 1],\n",
    "                   X_train_trans[selected_df.Pruefling_ID==Pruefling_ID, 2],\n",
    "                   c=[mycolors[status] for status in encoder.transform(selected_df.loc[selected_df.Pruefling_ID==Pruefling_ID,\"Status\"])],\n",
    "                   marker=markers[idx],\n",
    "                   s=140,                     \n",
    "                   edgecolors=\"black\",\n",
    "                   label=Pruefling_ID)\n",
    "    \n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.set_zlabel(\"x3\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(str(len(X_transformed))\n",
    "        + \" statt 2 oder 3 Komponenten, für eine grafische Darstellung ein Modell mit n_components = 2 oder 3 trainieren.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Modelle validieren - Kennzahlen berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne Stress-Wert\n",
    "from sklearn import metrics\n",
    "\n",
    "similarities = metrics.euclidean_distances(X_train)\n",
    "dist_lowtriang = np.tril(similarities, -1)\n",
    "dist_quadr = np.square(dist_lowtriang)\n",
    "print(\"Stress-Wert:\\t\" + str(\"%.3f\" % np.sqrt(model.stress_ / np.sum(dist_quadr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Visualisierung\n",
    "In diesem Schritt werden automatisch mehrere MDS mit unterschiedlicher Anzahl von Dimensionen, n_components, berechnet. Für jede wird der Stress Wert bestimmt und anschließend als Grafik ausgegeben. \n",
    "\n",
    "__Achtung:__ Die Berechnung kann etwas dauern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne Stress 1-Wert für Modelle\n",
    "n_dims = [2, 3, 4, 5, 6]\n",
    "results = []\n",
    "for n_dim in n_dims:\n",
    "    # Modell erstellen\n",
    "    model = MDS(dissimilarity=\"euclidean\",\n",
    "                n_components=n_dim,\n",
    "                random_state=my_seed, \n",
    "                n_jobs=-2)\n",
    "    # Skalierung durchführen\n",
    "    X_train_trans = model.fit_transform(X_train)\n",
    "    similarities = metrics.euclidean_distances(X_train)\n",
    "    dist_lowtriang = np.tril(similarities, -1)\n",
    "    dist_quadr = np.square(dist_lowtriang)\n",
    "    stress_1 = np.sqrt(model.stress_ / np.sum(dist_quadr))\n",
    "    results.append(stress_1)\n",
    "\n",
    "# Visualisierung\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(n_dims, results, \"o--\")\n",
    "plt.plot([2, 6], [0.2, 0.2])\n",
    "plt.plot([2, 6], [0.1, 0.1])\n",
    "plt.plot([2, 6], [0.05, 0.05])\n",
    "plt.plot([2, 6], [0.025, 0.025])\n",
    "plt.xlabel(\"Anzahl Dimensionen nach Transformation\")\n",
    "plt.ylabel(\"Stress-Wert\")\n",
    "plt.title(\"Stress 1-Wert über Anzahl an Dimensionen\")\n",
    "plt.legend([\"data\", \"gering\", \"ausreichend\", \"gut\", \"ausgezeichnet\"], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MLiP)",
   "language": "python",
   "name": "python-mlip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
