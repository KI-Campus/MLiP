{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLiP Gaussian Naive Bayes am Beispiel Lilienbestimmung (IRIS)\n",
    "Kurs Maschinelles Lernen in der Produktion\n",
    "\n",
    "Ziel des Notebooks ist die Anwendung des Gaussian Naive-Bayes Verfahren anhand des Datensatzes Lilienbestimmung IRIS. Bei diesem Beispiel sollen die drei Arten IRIS Setosa, Virginica und Versicolor anhand der Länge und Breite der Kelchblätter und Kronblätter erkannt werden.  \n",
    "Fun Fact: Dies ist eines der meist analysierten Beispiele im Bereich des Maschinellen Lernens.\n",
    "\n",
    "![Bild konnte nicht geladen werden! IRIS Setosa](Iris_Setosa.jpg)\n",
    "Bild der IRIS Setosa Quelle: https://www.flickr.com/photos/lakeclarknps/37289883896 (No Copyright)\n",
    "\n",
    "### Prozessschritte Data-Mining:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bild konnte nicht geladen werden! 1. Daten erfassen - 2. Daten erkunden - 3. Daten vorbereiten - 4. Modelle bilden - 5. Modelle validieren - 6. Modell testen](Prozess_Modellentwicklung_v2.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Einstellungen für die Grafikausgabe\n",
    "style = 'seaborn-whitegrid'\n",
    "plt.style.use(style)\n",
    "plt.rcParams.update({'font.size': 14})  # Schriftgröße aller Textzeichen im Graphen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TODO:\n",
    "* Wähle eine Zahl zwischen 1 und 100 für die Generierung deiner spezifischen Zufallszahlen my_seed=\n",
    "\n",
    "(Wähle für alle Notebooks in allen Übungen immer die gleiche Zahl (z.B. den Tag deines Geburtstags), dann sind die Ergebnisse der verschiedenen Machine-Learning-Verfahren vergleichbar da dann alle Notebooks mit der \"gleichen\" Folge an Zufallszahlen arbeiten)\n",
    "\n",
    "AUSGABE:\n",
    "* Gewählte Zufallszahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Seed für eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Ausgabe gewählte Zufallszahlen\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten erfassen - Daten importieren\n",
    "Import der Daten mittels der read_csv-Funktion von Pandas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade Datensatz\n",
    "df = pd.read_csv(\"Daten_Schwertlilien.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Daten erkunden - Ausgabe Datensatz\n",
    "Ziel der Datenerkundung ist es einen Einblick in die Daten zu bekommen. Wir wollen verstehen wie der Datensatz aufgebaut ist.  \n",
    "* Welche Einflussgrößen gibt es?  \n",
    "* Wie sind die Werte der einzelnen Einflussgrößen verteilt? \n",
    "* Gibt es Auffälligkeiten bei den Daten? \n",
    "* Gibt es Ausreißer? \n",
    "* Kann man eine Unterschied zwischen den Klassen in den Daten erkennen? \n",
    "* Lassen sich Einflüße auf die Zielgröße erkennen? \n",
    "* Welche Art von Klassifikator könnte geeignet sein? \n",
    "\n",
    "TODO: \n",
    "* Schreibe die Code-Zeile, um dir die ersten 10 Zeilen das Datensatzes anzuzeigen\n",
    "* Hilfe dafür findest du auch im Cheat_Sheet_Daten_erkunden\n",
    "\n",
    "AUSGABE:\n",
    "* Tabelle mit ersten Zeilen das Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der ersten Zeilen des Datensatzes\n",
    "df.head(TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt 4 Einflussgrößen im Datensatz IRIS, die Länge und Breite jeweils vom Kelch- und Kronblatt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Daten erkunden - Datensatz spaltenweise beschreiben\n",
    "Berechnung von statistischen Kennzahlen, die die numerischen Daten beschreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erkenntnisse: \n",
    "* Die Anzahl der Beipsiele (count) ist immer gleich, somit gibt es keine fehlende Werte. \n",
    "* Die Streuung und der Range (Breite des Wertebereichs) unterscheiden sich mitunter deutlich.\n",
    "* Keine Ausreißer anhand statistischer Werte erkennbar, Min und Max weichen nicht stark ab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Daten erkunden - Datensatz visualisieren\n",
    "Für die Visualisierung von Datensätzen für die Klassifikation empfiehlt sich der Pairplot von Seaborn. Dabei handelt es sich um eine Scatter-Matrix, bei der die Datenpunkte gemäß der Zielklasse eingefärbt werden.   \n",
    "Bei der Visualisierung von großen Datensätzen ist Vorsicht geboten. \n",
    "* Bei zu vielen Spalten wird die Darstellung unübersichtlich. Es empfiehlt sich eine Auswahl der Spalten vorzunehmen. \n",
    "* Bei zu vielen Zeilen, also Datenpunkte, dauert die Erstellung des Plottes mitunter sehr lang. Hier reicht oft eine zufällige Auswahl der Datenpunkte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung Klassenzugehörigkeits-Matrix\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df, hue=\"Lilienart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Daten vorbereiten\n",
    "Für diese Aufgabe ist nur ein Schritt notwendig:\n",
    "* Die Aufteilung in Trainings- und Testdaten\n",
    "\n",
    "Die Normierung der Daten ist für den Gaussian Naive Bayes Klassifikator nicht notwendig. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Daten vorbereiten - Aufteilung in Trainings- und Testdaten sowie X und y\n",
    "Meist bekommt man einen Datensatz und muss die Aufteilung der Daten in Trainings- und Testdaten selbst vornehmen.   \n",
    "Am einfachsten geht das mit der Funktion train_test_split.  \n",
    "Diese teilt gleichzeitig die Eingangsdaten (X) und Zielgröße (y) auf.  \n",
    "Wichtige Einstellungen:  \n",
    "* Split festlegen, es empfiehlt sich ein Anteil der Trainingsdaten von 0.6 - 0.9. Je nachdem wie groß der Datensatz ist. \n",
    "* Für die Reproduzierbarkeit der Ergebnisse, sollte der random_state gesetzt werden, da die Auswahl zufällig erfolgt. \n",
    "* Bei Klassifikationsproblemen erfolgt die Aufteilung so, dass die Verteilung der Zielklassen beim Trainings und Test etwa gleich sind \n",
    "* Es empfiehlt sich die Daten zu mischen bevor sie aufgeteilt werden (shuffle=True). Allerdings ist dies die Standardeinstellung und kann auch weggelassen werden.\n",
    "\n",
    "\n",
    "TODO:\n",
    "* Setze für train_size einen Wert zwischen 0.6 und 0.9 ein\n",
    "* Beispiel: Ein Wert von 0.8 bedeutet der Datensatz wird in 80% Trainingsdaten und 20% Testdaten unterteilt.\n",
    "\n",
    "AUSGABE:\n",
    "* Größe der Datensätze\n",
    "* Variablen in X und in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen in Trainings- und Testdaten\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Angabe des Anteils der Trainingsdaten\n",
    "train_size = TODO  # Wert zwische 0 und 1, Anteil an Trainingsdaten\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=[\"Lilienart\"]),  # DataFrame nur mit Einflussgrößen, daher drop(weglassen) der Lilienart \n",
    "    df[\"Lilienart\"],  # Angabe der Zielgröße bzw. Übergabe der entsprechenden Daten\n",
    "    test_size= 1 - train_size,\n",
    "    shuffle=True,\n",
    "    random_state=my_seed\n",
    ")\n",
    "\n",
    "\n",
    "# Ausgabe Datensätze und Anzahl Datenpunkte\n",
    "print(\"\\nAnzahl Traingsdaten: \\t\" + str(len(y_train)) + \" / \" + str(len(df)))\n",
    "print(\"Anzahl Testdaten: \\t\" + str(len(y_test)) + \" / \" + str(len(df)))\n",
    "print(\"\\nX:\\t\" + str(list(X_train)))\n",
    "print(\"y:\\t[Lilienart]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelle trainieren\n",
    "In diesem Schritt wird das Modell imporiert, erstellt und trainiert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modelle bilden - Modell importieren und erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren des benötigten Modells\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Erstelle Modell\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modelle bilden - Modell trainieren\n",
    "Modell wird mit den normierten Trainingsdaten trainiert\n",
    "\n",
    "TODO:\n",
    "* Setze die Trainingsdaten in die .fit-Funktion ein (X_train und y_train) \n",
    "\n",
    "AUSGABE:\n",
    "* trainiertes Gaussian Naive Bayes Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainiere das Modell\n",
    "model = model.fit(TODO, TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Modelle bewerten (anhand Trainingsdaten)\n",
    "Wir berechnen die Kennzahlen auch für die Trainingsdaten: \n",
    "* damit wir erkennen, wie gut das Modell die Trainingsdaten erlernen kann\n",
    "* damit wir die Kennzahlen vom Training später mit den Kennwerten von der Validierung bzw. Test vergleichen können. \n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "TODO:\n",
    "*  Setze X_train in die .predict-Funktion ein, um eine Vorhersage für die Trainingsdaten zu berechnen \n",
    "* Übergebe der accuray_score-Funktion y_train und y_train_pred, um die Genauigkeit auf den Trainingsdaten zu berechnen. \n",
    "\n",
    "AUSGABE:\n",
    "* Genauigkeit des Modells auf Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Accuracy für die Trainingsdaten\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Vorhersage der Trainingsdaten mit Modell\n",
    "y_train_pred = model.predict(TODO)\n",
    "\n",
    "print('Accuracy für die Trainingsdaten:')\n",
    "accuracy_score(TODO, TODO) \n",
    "# Hinweis: in dieser Kurzform ist es wichtig, erst die wahren Werte, dann die vorhersagegten Werten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1-Score\n",
    "TODO:\n",
    "* Übergebe der F1-Score-Funktion y_train und y_train_pred, um den F1-Score auf den Trainingsdaten zu berechnen. \n",
    "\n",
    "AUSGABE:\n",
    "* F1-Score des Modells für die Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Accuracy für die Trainingsdaten\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F1-Score für die Trainingsdaten:')\n",
    "f1_score(TODO, TODO, average='weighted')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Modelle validieren - Modell validieren\n",
    "Entfällt da nur 1 Modell trainiert wurde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modell testen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Modell testen - Genauigkeit auf Testdaten\n",
    "Wir berechnen nun die Kennzahlen für die Testdaten: \n",
    "* damit wir abschließend bewerten können, wie gut das Modell bei unbekannten Daten wirklich funktioniert\n",
    "* damit wir erkennen, wie gut das Modell sich später in der Anwendung bewähren wird\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "TODO:\n",
    "*  Setze X_test in die .predict-Funktion ein, um eine Vorhersage für die Trainingsdaten zu berechnen \n",
    "* Übergebe der accuray_score-Funktion y_test und y_test_pred, um die Genauigkeit auf den Testdaten zu berechnen. \n",
    "\n",
    "AUSGABE:\n",
    "* Genauigkeit des Modells auf Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersage der Trainingsdaten mit Modell\n",
    "y_test_pred = model.predict(TODO)\n",
    "\n",
    "print('Accuracy für die Testsdaten:')\n",
    "accuracy_score(TODO, TODO) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1-Score\n",
    "TODO:\n",
    "* Übergebe der F1-Score-Funktion y_test und y_test_pred, um den F1-Score auf den Trainingsdaten zu berechnen. \n",
    "\n",
    "AUSGABE:\n",
    "* Genauigkeit des Modells auf Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Accuracy für die Trainingsdaten\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F1-Score für die Testsdaten:')\n",
    "f1_score(TODO, TODO, average='weighted')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Modell testen - Visualisierung der Modellgüte (Konfusionsmatrix)\n",
    "\n",
    "Für die Erstellung der Konfusionsmatrix gibt es zwei Varianten, die von dem Objekt ConfusionMatrixDisplay als Funktionen (korrekt handelt es sich hier um Methoden) bereitgestellt werden.  \n",
    "Die Funktion .from_predictions bekommt die echten Werte und die Vorhergesagten Werte mit denen eine Konfusionsmatrix erstellt wird.  \n",
    "Die Funktion .from_estimator bekommt das Modell, die Daten (Eingangsdaten X und Zielgröße y), um die Konfusionsmatrix zu erstellen. \n",
    "\n",
    "TODO: \n",
    "* Übergebe der ConfusionMatrixDisplay.from_predictions-Funktion y_test und y_test_pred für die Erstellung der Konfusionsmatrix\n",
    "\n",
    "AUSGABE:\n",
    "* Konfusionsmatrix für die Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe Konfusionsmatrix\n",
    "\n",
    "# Importieren der Funktion: ConfusionMatrixDisplay\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "#Erstellen der Konfusionsmatrix mit Hilfe des trainierten Modells\n",
    "ConfusionMatrixDisplay.from_predictions(TODO, TODO, xticks_rotation=45)\n",
    "plt.title('Konfusionsmatrix auf Testdaten')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Visualisierung mittels Decision Boundary\n",
    "\n",
    "Dieser Abschnitt soll zeigen, wie man eine Decision Boundary erstellen kann. Das Ganze ist technisch etwas aufwändiger und ist nur als Bonus gedacht.  \n",
    "\n",
    "Für die Decision Boundary wird ein neues Modell erstellt, das nur die beiden Größen Länge Kelchblatt und Breite Kelchblatt nutzt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritte 3 Daten vorbereitung und 4 Modell trainieren \n",
    "\n",
    "# Daten vorbereiten\n",
    "train_size = 0.8  # Wert zwische 0 und 1, Anteil an Trainingsdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=[\"Lilienart\", 'Länge Kronblatt', 'Breite Kronblatt']),\n",
    "    df[\"Lilienart\"],\n",
    "    test_size=1 - train_size,\n",
    "    shuffle=True,\n",
    "    random_state=my_seed\n",
    ")\n",
    "# Modell trainieren\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Grid für Modellausgabe\n",
    "x1_grid = np.linspace(X_train[\"Länge Kelchblatt\"].min(), X_train[\"Länge Kelchblatt\"].max(), 250)\n",
    "x2_grid = np.linspace(X_train[\"Breite Kelchblatt\"].min(), X_train[\"Breite Kelchblatt\"].max(), 250)\n",
    "xx1, xx2 = np.meshgrid(x1_grid, x2_grid)\n",
    "\n",
    "# Berechne Modellvorhersage im Plotbereich\n",
    "z = model.predict(pd.DataFrame({\"Länge Kelchblatt\": xx1.ravel(), \"Breite Kelchblatt\": xx2.ravel()}))\n",
    "\n",
    "# Umwandeln der Klassennamen in Klassennamen\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "z = le.fit_transform(z)\n",
    "\n",
    "# Formatkonvertierung des Ergegebnisses für Plot\n",
    "Z = np.asarray(z).reshape(250, 250)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "plt.title(\n",
    "    \"Modellvorhersage und Datensätze (Train = Kreis, Test = Raute)\"\n",
    ")\n",
    "plt.xlabel(\"Länge Kelchblatt\")\n",
    "plt.ylabel(\"Breite Kelchblatt\")\n",
    "plt.contourf(xx1, xx2, Z, cmap=plt.cm.brg)\n",
    "scatter = plt.scatter(\n",
    "    X_train[\"Länge Kelchblatt\"],\n",
    "    X_train[\"Breite Kelchblatt\"],\n",
    "    cmap=plt.cm.brg,\n",
    "    c=le.transform(y_train),\n",
    "    marker=\"o\",\n",
    "    alpha=0.5,\n",
    "    edgecolors=\"black\",\n",
    "    s=70\n",
    ")\n",
    "plt.scatter(\n",
    "    X_test[\"Länge Kelchblatt\"],\n",
    "    X_test[\"Breite Kelchblatt\"],\n",
    "    cmap=plt.cm.brg,\n",
    "    c=le.transform(y_test),\n",
    "    marker=\"D\",\n",
    "    edgecolors=\"black\",\n",
    "    s=70\n",
    ")\n",
    "#add legend with class names\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=list(le.classes_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MLiP)",
   "language": "python",
   "name": "python-mlip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
