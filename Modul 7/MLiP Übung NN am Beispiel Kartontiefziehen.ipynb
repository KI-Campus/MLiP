{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLiP Neuronale Netze am Beispiel Kartontiefziehen\n",
    "Kurs Maschinelles Lernen in der Produktion\n",
    "\n",
    "### In diesem Notebook wird ein Entscheidungsbaum auf das Anwendungsbeispiel Kartontiefziehen trainiert.\n",
    "\n",
    "Tiefziehen ist ein weit verbreitetes Umformverfahren. Bei diesem Beispiel wird jedoch kein Halbzeug aus Metall sondern aus Kartonage umgeformt. Die Besonderheit dabei ist, das Kartonage ein Fasermaterial ist und somit ein richtungsabhängiges Umformverhalten aufweist. Dadurch entstehen beim Umformen Falten. Jedoch ist bei diesem Prozess das Ziel einen möglichen ebenen und gleichmäßigen Flansch zu erhalten. \n",
    "\n",
    "Im Datensatz \"Kartontiefziehen\" werdne mehrere Eingangsparameter des Umformprozesses, wie bspw. Faltenhalterkraft und Temperaturen variert. Ziel ist es ein Vorhersagemodell zu entwickeln, mit dem man die maximale Höhe der Falten vorhersagen kann.  \n",
    "\n",
    "### Data-Mining-Prozess:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Prozess_Modellentwicklung_v2.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import time\n",
    "\n",
    "#Einstellungen für die Grafikausgabe\n",
    "style = 'seaborn-whitegrid'\n",
    "plt.style.use(style)\n",
    "plt.rcParams.update({'font.size': 14})  # Schriftgröße aller Textzeichen im Graphen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Wähle eine Zahl zwischen 1 und 100 für die Generierung deiner spezifischen Zufallszahlen my_seed=\n",
    "\n",
    "(Wähle für alle Notebooks in allen Übungen immer die gleiche Zahl (z.B. den Tag deines Geburtstags), dann sind die Ergebnisse der verschiedenen Machine-Learning-Verfahren vergleichbar da dann alle Notebooks mit der \"gleichen\" Folge an Zufallszahlen arbeiten)\n",
    "\n",
    "AUSGABE:\n",
    "* Gewählte Zufallszahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Ausgabe gewählte Zufallszahlen\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Daten erfassen - Daten importieren\n",
    "\n",
    "Import der Daten mittels der read_csv-Funktion von Pandas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz importieren\n",
    "df = pd.read_csv('Kartontiefziehen.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Daten erkunden\n",
    "Infos zu den Daten:\n",
    "* f_fh,\tFaltenhalterkraft in N\n",
    "* s_0,\tAnfangsstärke Karton in mm\n",
    "* t_fal,\tFaltehaltertemperatur in °C\n",
    "* t_stem,\tStempeltemperatur in °C\n",
    "* t_zb,\tZiehbüchsentemperatur in °C\n",
    "* f_punch_max,\tmaximale Stempelkraft\n",
    "* thick_red_max,\tmaximale Kartonausdünnung am Ende der Simulation in % der Anfangsstärke\t\n",
    "* flx,\tFlanscheinzug in X-Richtung in mm\n",
    "* fly,\tFlanscheinzug in Y-Richtung in mm\n",
    "* h_falten,\tFaltenhöhe in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz anzeigen\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz beschreiben\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeige Streudiagramm aller Variablenkombinationen an\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(df, alpha=0.2, figsize=(16, 16))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Daten vorbereiten - Daten aufteilen\n",
    "Der Datensatz wird in Trainings- und Testdaten aufgeteilt.  \n",
    "__Achtung__, die Trainingsdaten werden automatisch im Schritt GridSearch nochmals in Trainings- und Validationsdaten aufgeteilt.  \n",
    "\n",
    "TODO:\n",
    "- Lege den Anteil der Trainingsdaten mittels train_size fest  \n",
    "\n",
    "Ausgabe:  \n",
    "- Anzahl Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten in Trainings- und Test aufteilen\n",
    "\n",
    "# Verhältnis Trainings- und Testdaten\n",
    "train_size = TODO\n",
    "\n",
    "# Aufteilung in Trainings- und Testdaten\n",
    "X_train_, X_test_, y_train, y_test = train_test_split(df.drop(columns=['h_falten']),\n",
    "                                                      df['h_falten'], \n",
    "                                                      train_size=train_size, \n",
    "                                                      random_state=my_seed)\n",
    "\n",
    "# Ausgabe Datensätze und Anzahl Datenpunkte\n",
    "print(\"\\nAnzahl Traingsdaten: \\t\\t\" + str(len(y_train)) + \" / \" + str(len(df)))\n",
    "print(\"Anzahl Testdaten: \\t\\t\" + str(len(y_test)) + \" / \" + str(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Daten vorbereiten - Daten normieren\n",
    "Die Normierung der Daten wird bei neuronalen Netzen stark empfohlen, weil es dem Netz das lernen erleichtert.  \n",
    "\n",
    "Es stehen grundsätzlich der StandardScaler, der MinMaxScaler und der MaxAbsScaler zur Verfügung. Für dieses Beispiel wurde der StandardScaler vorbereitet.\n",
    "\n",
    "Es können auch andere Scaler verwendet werden, die müssen entsprechend importiert werden und der Befehl scaler = ... muss angepasst werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalierung der Daten mit dem StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train_.values), index=X_train_.index, columns=X_train_.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test_.values), index=X_test_.index, columns=X_test_.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modelle bilden - Modell importieren\n",
    "Zuerst müssen wir das SVM Modell importieren, damit wir es später nutzen können. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren des Modells\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modelle bilden - Optimale Hyperparameter mittels Gittersuche bestimmen\n",
    "\n",
    "Um die optimalen Hyperparameter für das Neuronale Netz zu finden, wird eine __Gittersuche__ durchgeführt:\n",
    "\n",
    "TODO:\n",
    "- Schreibe die zu variierenden Hyperparameter listenweise in ein Dictionary \n",
    "- Die Struktur eines Neuronalen Netzes (Anzahl an hidden layers sowie Neuronen je hidden layer) wird wie folgt angegeben:\n",
    "    - hidden_layers_sizes = (3,) -> 1 hidden layer mit 3 Neuronen\n",
    "    - hidden_layers_sizes = (3,2) -> 2 hidden layers mit 3 und 2 Neuronen\n",
    "    - hidden_layers_sizes = (5,5,2) -> 3 hidden layers mit 5, 5 und 3 Neuronen\n",
    "    - Zur Erinnerung: Die input layer hat soviele Neuronen wie Inputparameter, die output layer hat bei der Regression 1 Neuron  \n",
    "    \n",
    "__Achtung__, es wurde fest der solver lbfgs (nicht zwingend beste Möglichkeit),\\\n",
    " als random state der seed: random_state=my_seed\\\n",
    " und die maximale Anzahl der Iterationen (max_iter) angepasst.\\\n",
    " Diese Werte müssen nicht variert werden und wurden direkt dem Modell gegeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition der Hyperparamter für die Gittersuche\n",
    "hyper_parameters = {'hidden_layer_sizes': [TODO], \n",
    "                     TODO\n",
    "                    }     \n",
    "\n",
    "# Erstellung des MLP Modells\n",
    "model = MLPRegressor(max_iter=50000, solver='lbfgs', random_state=my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Modelle bilden - Modelle per Gittersuche trainieren\n",
    "Durchführen der Gittersuche  \n",
    "\n",
    "AUSGABE:\n",
    "* Anzahl der getesteten Hyperparameterkombinationen\n",
    "* Zeitdauer für Gittersuche\n",
    "* bestes Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Durchführung der Gittersuche\n",
    "start_timer = time.monotonic()\n",
    "gridSearch = GridSearchCV(model, hyper_parameters, return_train_score=True, scoring='neg_mean_absolute_error', cv=5, n_jobs=-2)\n",
    "gridSearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nDie Gittersuche (\" + str(len(pd.DataFrame(gridSearch.cv_results_)))\n",
    "      + \" Kombinationen) hat \" + str(\"%.1f\" % (time.monotonic() - start_timer))\n",
    "      + \" Sekunden gedauert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Modelle validieren - GridSearch Ergebnisse begutachten\n",
    "In der Variablen GridSearch sind nun die Ergebnisse der Gittersuche gespeichert.  \n",
    "\n",
    "Mit dem Befahl GridSearch.cv_results_ bekommen wir die Ergebnis-Tabelle der Gittersuche (hier: besten 5 Ergebnisse). \n",
    "\n",
    "TODO:\n",
    "- Vergleiche die Trainings- und Testergebenis für die verschiedenen Splits, um sicherzustellen, dass ein gutes Modell gefunden wurde und kein Overfitting vorliegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Ergebnisse\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.DataFrame(gridSearch.cv_results_).sort_values(\"mean_test_score\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Modelle validieren - Modell auswählen \n",
    "Ausgabe der besten Hyperparameter der Gittersuche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beste Kombination der Hyperparameter\n",
    "gridSearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraktion des besten Modells aus der Gittersuche.  \n",
    "__Achtung__, dieses Modell wurde bereits mit allen Trainingsdaten trainiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraktion des Modells\n",
    "model = gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Modelle validieren - Bewertung des Trainings\n",
    "Bewertung des Trainings mittels dem MAE. \n",
    "\n",
    "TODO:\n",
    "- Schreibe den Code für den MAE des Modells auf den Trainingsdaten\n",
    "- Hinweis: Import der Funktion nicht vergessen\n",
    "\n",
    "AUSGABE:\n",
    "- MAE auf den Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersage der Trainingsdaten mit Modell\n",
    "y_train_pred = TODO\n",
    "\n",
    "# Berechnung des MAE\n",
    "print('MAE für die Trainingsdaten:')\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisierung der Modell-Vorhersage über den realen Werten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe Graph\n",
    "min_train, max_train = y_train.min(), y_train.max()\n",
    "plt.figure(figsize=(9, 8))\n",
    "plt.plot(y_train, np.squeeze(y_train_pred), \"o\", alpha=0.4)\n",
    "plt.plot([min_train, max_train], [min_train, max_train], \"--\", c=(0, 0, 0))\n",
    "plt.xlabel(\"reale Faltenhöhe\")\n",
    "plt.ylabel(\"vorhergesagte Faltenhöhe\")\n",
    "plt.title(\"Vorzugsmodell - Trainingsdaten\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Modell testen & anwenden - Bewertung anhand der Testdaten\n",
    "\n",
    "Um die Qualität/Güte des Modells zu bestimmen, berechnen wir nun den MAE für die Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersage mit Modell anhand den Testdaten\n",
    "y_test_pred = TODO\n",
    "\n",
    "# Berechnug des MAE für die Testdaten\n",
    "print('MAE für die Testdaten:')\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisierung der Modell-Vorhersage über den realen Werten.\n",
    "\n",
    "Achtung:  \n",
    "Falls das Ergebnis etwas überrascht, gerne die Auflösung ansehen, dort gibt es eine Erklärung dazu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe Graph\n",
    "min_test, max_test = y_test.min(), y_test.max()\n",
    "fig = plt.figure(figsize=(9, 8))\n",
    "plt.plot(y_test, y_test_pred, \"o\", alpha=0.4)\n",
    "plt.plot([min_test, max_test], [min_test, max_test], \"--\", c=(0, 0, 0))\n",
    "plt.xlabel(\"reale Faltenhöhe\")\n",
    "plt.ylabel(\"vorhergesagte Faltenhöhe\")\n",
    "plt.title(\"Vorzugsmodell - Testdaten\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MLiP)",
   "language": "python",
   "name": "python-mlip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
