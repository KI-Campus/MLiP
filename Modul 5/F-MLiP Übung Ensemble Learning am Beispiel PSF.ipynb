{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLiP  Ensemble Learning am Beispiel PSF\n",
    "\n",
    "#### In diesem Notebook werden Verfahren des Ensemble Learnings für Decision Trees anhand des Anwendungsbeispiels Profilschienenführung (PSF) geübt. \n",
    "\n",
    "Linearführungen und Profilschienenführungen sind für einen nicht unbedeutenden Teil der Ausfälle bei Werkzeugmaschinen.\n",
    "Typische Fehlerfälle die dabei auftreten sind Mangelschmierungen, Pittings an Laufbahnen oder an den Wälzkörpern. In diesem Beispiel ist aber der grundlegende Zustand der PSF von Interesse, d.h. ist der Zustand fehlerfrei (OK) oder machen sich Verschleißerscheinungen (Ausfall) deutlich. \n",
    "\n",
    "Für dieses Beispiel wurden mehrere Profilschienen unter Belastung bis zu ihrem Lebensende verfahren. Die dabei auftretenden Fehler sind natürlich entstanden. Dementsprechend unterscheiden Sie sich sowohl in der Art als auch in der Stärke.\n",
    "\n",
    "Während der Versuche wurde mittels einem 3-achsigen MEMS-Sensor die Beschleunigungen, in Verfahrrichtung (Acc_X)\n",
    "in Richtung oder entgegen Erdmittelpunkt (Acc_Y) und orthogonal zu beiden in Richtung des Seitennormalenvektor des Versuchsstands (Acc_Z) aufgenommen. Die entsprechenden Zeitreihen:\n",
    "<table><tr>\n",
    "<td> <img src=\"MLiP_PSF_Messfahrt_gut.png\" alt=\"Status OK\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src=\"MLiP_PSF_Messfahrt_ausfall.png\" alt=\"Status Ausfall\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>\n",
    "Für diese Aufgabe wurde nur die Beschleunigung in Verfahrrichtung (Acc_X) verwendet. Deren Werte wurden bereits zu Features zusammengefasst, anhand denen nun ein Ensemble Learning Methode, Random Forest bzw. Gradient Boosting angewendet wird.\n",
    "\n",
    "\n",
    "### Data-Mining-Prozess:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bild konnte nicht geladen werden! 1. Daten erfassen - 2. Daten erkunden - 3. Daten vorbereiten - 4. Modelle bilden - 5. Modelle validieren - 6. Modell testen](Prozess_Modellentwicklung_v2.png \"ML Vorgehen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#Einstellungen für die Grafikausgabe\n",
    "style = 'seaborn-whitegrid'\n",
    "plt.style.use(style)\n",
    "plt.rcParams.update({'font.size': 14})  # Schriftgröße aller Textzeichen im Graphen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Wähle eine Zahl zwischen 1 und 100 für die Generierung deiner spezifischen Zufallszahlen my_seed=\n",
    "\n",
    "(Wähle für alle Notebooks in allen Übungen immer die gleiche Zahl (z.B. den Tag deines Geburtstags), dann sind die Ergebnisse der verschiedenen Machine-Learning-Verfahren vergleichbar da dann alle Notebooks mit der \"gleichen\" Folge an Zufallszahlen arbeiten)\n",
    "\n",
    "AUSGABE:\n",
    "* Gewählte Zufallszahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Ausgabe gewählte Zufallszahlen\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Daten erfassen - Daten importieren\n",
    "\n",
    "Import der Daten mittels der read_csv-Funktion von Pandas.  \n",
    "Achtung, es gibt zwei Datensätze, einen mit den Trainingsdaten und einen mit den Testdaten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade Datensatz\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Daten erkunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz anzeigen\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz beschreiben\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der No Information Rate (NIR)\n",
    "# also welche Genauigkeit wird erhalten, wenn immer ok vorhegesagt wird. \n",
    "\n",
    "NIR = len(df[df.Status=='OK'])/len(df)\n",
    "\n",
    "print('NIR / baseline für Bewertung der Accuracy: ' + str(round(NIR, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung Klassenzugehörigkeits-Matrix für zufällige Auswahl von 200 Datenpunkten\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df.sample(n=200), hue=\"Status\")\n",
    "plt.show()\n",
    "\n",
    "# Achtung, dies kann etwas dauern!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Daten vorbereiten - Encoding der Label\n",
    "\n",
    "Die Zielspalte liegt noch im String Format vor, damit können die Verfahren nicht umgehen. Daher wird mit der Funktion LabelEncoder von sklearn die String Werte 'OK' und 'Ausfall' in Zahlenwerte 0 und 1 umgewandelt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding des Status mittels dem Label Encoder\n",
    "# Import des LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialsierung\n",
    "le = LabelEncoder()\n",
    "\n",
    "# LabelEncoder bekommt zu transformierende Labels, erstellt internes Mapping\n",
    "le.fit(['OK', 'Ausfall'])\n",
    "\n",
    "# Beispielhafte Anwendung des LabelEncoder\n",
    "print('Beispiel LabelEncoder')\n",
    "print('Original Labels: \\t' + str(['Ausfall', 'OK', 'OK', 'Ausfall', 'OK']))\n",
    "print('Transformierte Labels: \\t' + str(le.transform(['Ausfall', 'OK', 'OK', 'Ausfall', 'OK'])))\n",
    "\n",
    "# Anwendung LabelEncoder auf DataFrame\n",
    "df = df.assign(status_enc = le.transform(df['Status']) )\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Daten vorbereiten - Aufteilung der Daten\n",
    "\n",
    "Einzelne Prüflinge können spezifische Charakteristika aufweisen. Daher kann es passieren, dass der ML Algorithmus diese Charakteristika und nicht die grundlegenden Zusammenhalte lernt. Durch die Bildung eines vollständig unabhängigen Testdatensatz wird sichergestellt, dass das Modell wirklich gut auf neue Versuche generalisiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Daten in Trainings- und Test aufteilen\n",
    "\n",
    "# Setting random seed for numpy\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "# zufällige Auswahl von 6 Prüflingen für den Testdatensatz\n",
    "test_IDs = np.random.choice(df['Pruefling_ID'].unique(),6)\n",
    "print('Ausgewählte Prüflinge für Testdatensatz: ' + str(test_IDs))\n",
    "\n",
    "# Aufteilung in Trainings und Testdatensatz\n",
    "df_test = df[df['Pruefling_ID'].isin(test_IDs)]\n",
    "df_train = df[~df['Pruefling_ID'].isin(test_IDs)]\n",
    "\n",
    "# Aufteilung in X und y jeweils für Trainings- und Testdaten\n",
    "X_train = df_train.drop(columns=['Messfahrt_ID', 'Pruefling_ID', 'Status', 'status_enc'])\n",
    "y_train = df_train['status_enc']\n",
    "\n",
    "X_test = df_test.drop(columns=['Messfahrt_ID', 'Pruefling_ID', 'Status', 'status_enc'])\n",
    "y_test = df_test['status_enc']\n",
    "\n",
    "# Ausgabe Datensätze und Anzahl Datenpunkte\n",
    "print(\"\\nAnzahl Traingsdaten: \\t\\t\" + str(len(y_train)) + \" / \" + str(len(df)))\n",
    "print(\"Anzahl Testdaten: \\t\\t\" + str(len(y_test)) + \" / \" + str(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Daten vorbereiten - Normierung der Daten\n",
    "__Optional__ können die Input-Parameter normiert werden.   \n",
    "Allerdings hat dies keine Auswirkungen auf die Performance der Entscheidungsbaum-basierten Verfahren. \n",
    "Daher wird hier auf diesen Schritt verzichtet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modell bilden - Modell importieren\n",
    "Zuerst müssen wir das Modell importieren, damit wir es später nutzen können. \n",
    "Die Übung kann dabei mit dem Random Forest und Gradient Boosting gelöst werden. \n",
    "\n",
    "TODO:\n",
    "- Importiere mindestens eins der beiden Modelle, Random Forest und Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere das Modell aus der Bibliothek sklearn\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hilfe zum Import:\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modelle bilden - Hyperparameter Tuning mittels Gittersuche\n",
    "\n",
    "Um die optimalen Werte für die Hyperparameter zu finden, wird eine Gittersuche mit Crossvalidation __GridSearchCV__ durchgeführt:\n",
    "1. Hyperparameter bestimmen\\\n",
    "Für die Ensemble Learning Verfahren RandomForest und GradientBoosting werden in diesem Notebook 3 Hyperparameter eingestellt:\n",
    "- n_estimators: Anzahl der Bäume, Suchbereich Liste [50, 100, 150, 200, 250]\n",
    "- min_samples_leaf: Minimale Anzahl der Beispiele je Blatt, Suchbereich Liste [1, 2, 3, 4]\n",
    "- max_depth: Maximale Tiefe der Bäume, Suchbereich numpy Array np.linspace(2,7,6) ergibt 6 Werte gleichverteilt von 2 bis 7, also (2, 3, 4, 5, 6, 7)  \n",
    "- random_state: Startwert Zufallszahlengenerator, fester Wert [my_seed].\n",
    "Für das Verfahren GradientBoosting empfiehlt es sich zudem die Lernrate als Hyperparameter zu optimieren. Damit aber die vordefinierten Hyperparameter für beide Verfahren funktionieren, wurde auf die Lernrate verzichtet.\\\n",
    "\\\n",
    "Die Hyperparameter werden als Dictionary gebraucht, das ist eine Datenstruktur mit mehreren Einträgen von key-Value Paaren, d.h. eindeutige Bezeichner (keys) und den zugehörigen Werten.\n",
    "\n",
    "\n",
    "2. Modell erstellen\\\n",
    "Wenn manche Hyperparameter kann man diese entweder als Hyperparameter in Schritt 1 mit aufnehmen oder direkt an das Modell übergeben. Da das Modell unklar ist, wurde der Hyperparameter random_state bereits in Schritt 1 der fixe Wert my_seed festgelegt. \n",
    "\n",
    "3. Gittersuche parameterieren\\\n",
    "In diesem Schritt werden Parameter für die Klasse GridSearchCV eingestellt und dann in einer Variable gespeichert.\\\n",
    "Parameter: \n",
    "* 1. Parameter: das ML-Modell, hier model \n",
    "* 2. Parameter: die Hyperparameter, hier hyper_parameters, diese müssen als dictionary gegeben sein (vgl. Schritt 1) \n",
    "* return_train_score=True, um die Trainingsergebnisse zu erhalten\n",
    "* cv=5, Anzahl der Folds, die gebildet werden \n",
    "* n_jobs=-2 Parallelisierung der Berechnung, alle bis auf ein Prozessorkern wird genutzt\n",
    "\n",
    "4. Modelle trainieren\\\n",
    "Das Training der Modelle erfolgt wieder mit dem fit Befehl. Diesem müssen die Trainingsdaten übergeben werden. \n",
    "\n",
    "TODO:\n",
    "- Erzeuge ein Modell, Random Forest oder Gradien Boosting Model, je nach Wunsch\n",
    "- Übergebe der GridSearchCV Klasse, das Modell (model) und die Hyperparameter (hyper_parameters)\n",
    "- Setze die Trainingsdaten in den .fit-Befehle ein (X_train und y_train)  \n",
    "- __Optional__ Ändere die Hyperparameter, um ein besseres Modell zu finden\n",
    "    \n",
    "AUSGABE:\n",
    "- Anzahl der getesteten Hyperparameterkombinationen\n",
    "- Zeitdauer für Gittersuche\n",
    "- bestes Modell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Werte für die Gittersuche/Hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "start_timer = time.monotonic()\n",
    "# 1. Hyperparameter bestimmen - für die Suche und Suchbereiche \n",
    "hyper_parameters = {\"n_estimators\": [50, 100, 150, 200, 250], \n",
    "                    \"min_samples_leaf\":  [1, 2, 3, 4], \n",
    "                    \"max_depth\": np.linspace(2,7,6),\n",
    "                    \"random_state\": [my_seed]}\n",
    "\n",
    "# 2. Modell erzeugen\n",
    "model = TODO\n",
    "\n",
    "# 3. Gittersuche parametrieren\n",
    "gridSearch = GridSearchCV(TODO, TODO, return_train_score=True, cv=5, n_jobs=-2)\n",
    "# 4. Modelle trainieren\n",
    "gridSearch = gridSearch.fit(TODO, TODO)\n",
    "print(\"\\nDie Gittersuche (\" + str(len(pd.DataFrame(gridSearch.cv_results_)))\n",
    "      + \" Kombinationen) hat \" + str(\"%.1f\" % (time.monotonic() - start_timer))\n",
    "      + \" Sekunden gedauert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Modelle validieren - GridSearch Ergebnisse begutachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Variablen GridSearch sind nun die Ergebnisse der Gittersuche gespeichert.  \n",
    "\n",
    "Mit dem Befahl GridSearch.cv_results_ bekommen wir die Ergebnis-Tabelle der Gittersuche (hier: besten 5 Ergebnisse). \n",
    "\n",
    "TODO: \n",
    "- Ergebnisse bewerten\\\n",
    "Dabei gilt es in der Tabelle zu überprüfen, ob die \"test_scores\" also Ergebnisse der Valdierung gleichmäßig gut sind und es kein Overfitting gibt (vgl. splitxy_test_score mit splitxy_train_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Ergebnisse\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.DataFrame(gridSearch.cv_results_).sort_values(\"mean_test_score\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Modelle validieren - Modell auswählen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach dem GridSearchCV Training interessiert uns, mit welchen Hyperparameter das beste Ergebnis bei der Crossvalidation erzielt wurde. \n",
    "TODO:\n",
    "- Setze den Befehl \"best_params_\" ein, um die entsprechende Methode der Klasse gridsearch aufzurufen\n",
    "\n",
    "Ausgabe:\n",
    "- Hyperparameter mit dem besten Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beste Kombination der Hyperparameter\n",
    "gridSearch.TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun muss das Modell mit den optimalen Hyperparametern erstellt und dann mit den Trainingsdaten trainiert werden.  \n",
    "Diese Aufgabe übernimmt bereits die GridSearch-Funktion. Somit muss das beste Modell nur noch extrahiert werden. \n",
    "\n",
    "TODO:\n",
    "- Setze den \"best_estimator_\" ein, um die entsprechende Methode aufzurufen und das beste Modell zu extrahieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraktion des Modells\n",
    "model = gridSearch.TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Modelle validieren - Bewertung des Trainings\n",
    "Wir berechnen die Genauigkeit des Modells auf den Trainingsdaten (richtige Vorhersagen/alle Vorhersagen).\n",
    "\n",
    "TODO:\n",
    "* Vorhersage auf den Trainingsdaten\n",
    "* Genaugigkeit auf den Trainingsdaten\n",
    "* F1-Score der Trainigsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Vorhersage basierend auf den Trainingsdaten\n",
    "y_train_pred = TODO\n",
    "\n",
    "# Berechne Genauigkeit auf den Trainingsdaten\n",
    "accuracy_train = TODO\n",
    "\n",
    "# Berechne den F1-Score auf den Trainingsdaten\n",
    "f1score_train = TODO\n",
    "\n",
    "# Ausgabe der Modellgenauigkeit\n",
    "print('Ergebnis für das Training:')\n",
    "print('Accuracy: \\t' + str(round(accuracy_train, 4)))\n",
    "print('F1-Score: \\t' + str(round(f1score_train, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Modell testen & anwenden - Genauigkeit auf Testdaten und Konfusionsmatrix\n",
    "\n",
    "Um die Qualität/Güte des Modells zu bestimmen wird dieses auf den Testdaten getestet und die Konfusionsmatrix ausgegeben.\n",
    "\n",
    "TODO:\n",
    "* Vorhersage auf den Testdaten\n",
    "* Genaugigkeit auf den Testdaten\n",
    "* F1-Score der Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Vorhersage basierend auf den Testdaten\n",
    "y_test_pred = TODO\n",
    "\n",
    "# Berechne Genauigkeit auf den Testdaten\n",
    "accuracy_test = TODO\n",
    "\n",
    "# Berechne den F1-Score auf den Testdaten\n",
    "f1score_test = TODO\n",
    "\n",
    "# Ausgabe der Modellgenauigkeit\n",
    "print('Ergebnis für den Test:')\n",
    "print('Accuracy: \\t' + str(round(accuracy_test, 4)))\n",
    "print('F1-Score: \\t' + str(round(f1score_test, 4)))\n",
    "\n",
    "\n",
    "# Visualisierung der Konfusionsmatrix\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
    "plt.grid()\n",
    "plt.title('Konfusionsmatrix auf Testdaten')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Bonus - Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe Graph Einfluss der Input-Variablen\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.bar(list(X_train), model.feature_importances_, align=\"center\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.ylabel('Importance Score')\n",
    "plt.xlabel('Feature')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MLiP)",
   "language": "python",
   "name": "python-mlip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
