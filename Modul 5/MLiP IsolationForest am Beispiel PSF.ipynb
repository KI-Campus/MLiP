{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLiP IsolationForest am Beispiel PSF\n",
    "\n",
    "#### In diesem Notebook wird der IsolationForest anhand des Anwendungsbeispiels Profilschienenführung (PSF) geübt. \n",
    "\n",
    "Linearführungen und Profilschienenführungen sind für einen nicht unbedeutenden Teil der Ausfälle bei Werkzeugmaschinen.\n",
    "Typische Fehlerfälle die dabei auftreten sind Mangelschmierungen, Pittings an Laufbahnen oder an den Wälzkörpern. In diesem Beispiel ist aber der grundlegende Zustand der PSF von Interesse, d.h. ist der Zustand fehlerfrei (OK) oder machen sich Verschleißerscheinungen (Ausfall) deutlich. \n",
    "\n",
    "Für dieses Beispiel wurden mehrere Profilschienen unter Belastung bis zu ihrem Lebensende verfahren. Die dabei auftretenden Fehler sind natürlich entstanden. Dementsprechend unterscheiden Sie sich sowohl in der Art als auch in der Stärke.\n",
    "\n",
    "Während der Versuche wurde mittels einem 3-achsigen MEMS-Sensor die Beschleunigungen, in Verfahrrichtung (Acc_X)\n",
    "in Richtung oder entgegen Erdmittelpunkt (Acc_Y) und orthogonal zu beiden in Richtung des Seitennormalenvektor des Versuchsstands (Acc_Z) aufgenommen. Die entsprechenden Zeitreihen:\n",
    "<table><tr>\n",
    "<td> <img src=\"MLiP_PSF_Messfahrt_gut.png\" alt=\"Status OK\" style=\"width: 350px;\"/> </td>\n",
    "<td> <img src=\"MLiP_PSF_Messfahrt_ausfall.png\" alt=\"Status Ausfall\" style=\"width: 350px;\"/> </td>\n",
    "</tr></table>\n",
    "Für diese Aufgabe wurde nur die Beschleunigung in Verfahrrichtung (Acc_X) verwendet. Deren Werte wurden bereits zu Features zusammengefasst, anhand denen nun ein Isolation Forest angewendet wird.\n",
    "\n",
    "\n",
    "### Data-Mining-Prozess:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bild konnte nicht geladen werden! 1. Daten erfassen - 2. Daten erkunden - 3. Daten vorbereiten - 4. Modelle bilden - 5. Modelle validieren - 6. Modell testen](Prozess_Modellentwicklung_v2.png \"ML Vorgehen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#Einstellungen für die Grafikausgabe\n",
    "style = 'seaborn-whitegrid'\n",
    "plt.style.use(style)\n",
    "plt.rcParams.update({'font.size': 14})  # Schriftgröße aller Textzeichen im Graphen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Wähle eine Zahl zwischen 1 und 100 für die Generierung deiner spezifischen Zufallszahlen my_seed=\n",
    "\n",
    "(Wähle für alle Notebooks in allen Übungen immer die gleiche Zahl (z.B. den Tag deines Geburtstags), dann sind die Ergebnisse der verschiedenen Machine-Learning-Verfahren vergleichbar da dann alle Notebooks mit der \"gleichen\" Folge an Zufallszahlen arbeiten)\n",
    "\n",
    "AUSGABE:\n",
    "* Gewählte Zufallszahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Ausgabe gewählte Zufallszahlen\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Daten erfassen - Daten importieren\n",
    "\n",
    "Import der Daten mittels der read_csv-Funktion von Pandas.  \n",
    "Achtung, es gibt zwei Datensätze, einen mit den Trainingsdaten und einen mit den Testdaten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade Datensatz\n",
    "df = pd.read_csv(\"CM_PSF_Features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Daten erkunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz anzeigen\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz beschreiben\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der No Information Rate (NIR)\n",
    "# also welche Genauigkeit wird erhalten, wenn immer ok vorhegesagt wird. \n",
    "\n",
    "NIR = len(df[df.Status=='OK'])/len(df)\n",
    "\n",
    "print('NIR / baseline für Bewertung der Accuracy: ' + str(round(NIR, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung Klassenzugehörigkeits-Matrix für zufällige Auswahl von 200 Datenpunkten\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df.sample(n=200), hue=\"Status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Daten vorbereiten - Encoding der Label\n",
    "\n",
    "Die Zielspalte liegt noch im String Format vor, damit können die Verfahren nicht umgehen. Daher wird mit der Funktion LabelBinarizer von sklearn die String Werte 'OK' und 'Ausfall' in Zahlenwerte 1 und -1 umgewandelt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding des Status mittels dem LabelBinarizer\n",
    "# Import des LabelBinarizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Initialsierung\n",
    "le = LabelBinarizer(neg_label=-1)\n",
    "\n",
    "# LabelBinarizer bekommt zu transformierende Labels, erstellt internes Mapping\n",
    "le.fit(['OK', 'Ausfall'])\n",
    "\n",
    "# Beispielhafte Anwendung des LabelBinarizer\n",
    "print('Beispiel LabelBinarizer')\n",
    "print('Original Labels: \\t' + str(['Ausfall', 'OK', 'OK', 'Ausfall', 'OK']))\n",
    "print('Transformierte Labels: \\t' + str(le.transform(['Ausfall', 'OK', 'OK', 'Ausfall', 'OK'])))\n",
    "\n",
    "# Anwendung LabelBinarizer auf DataFrame\n",
    "df = df.assign(status_enc = le.transform(df['Status']) )\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Daten vorbereiten - Aufteilung der Daten\n",
    "\n",
    "Einzelne Prüflinge können spezifische Charakteristika aufweisen. Daher kann es passieren, dass der ML Algorithmus diese Charakteristika und nicht die grundlegenden Zusammenhalte lernt. Durch die Bildung eines vollständig unabhängigen Testdatensatz wird sichergestellt, dass das Modell wirklich gut auf neue Versuche generalisiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Daten in Trainings- und Test aufteilen\n",
    "\n",
    "# Setting random seed for numpy\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "# zufällige Auswahl von 6 Prüflingen für den Testdatensatz\n",
    "test_IDs = np.random.choice(df['Pruefling_ID'].unique(),6)\n",
    "print('Ausgewählte Prüflinge für Testdatensatz: ' + str(test_IDs))\n",
    "\n",
    "# Aufteilung in Trainings und Testdatensatz\n",
    "df_test = df[df['Pruefling_ID'].isin(test_IDs)]\n",
    "df_train = df[~df['Pruefling_ID'].isin(test_IDs)]\n",
    "\n",
    "# Aufteilung in X und y jeweils für Trainings- und Testdaten\n",
    "X_train = df_train.drop(columns=['Messfahrt_ID', 'Pruefling_ID', 'Status', 'status_enc'])\n",
    "y_train = df_train['status_enc']\n",
    "\n",
    "X_test = df_test.drop(columns=['Messfahrt_ID', 'Pruefling_ID', 'Status', 'status_enc'])\n",
    "y_test = df_test['status_enc']\n",
    "\n",
    "# Ausgabe Datensätze und Anzahl Datenpunkte\n",
    "print(\"\\nAnzahl Traingsdaten: \\t\\t\" + str(len(y_train)) + \" / \" + str(len(df)))\n",
    "print(\"Anzahl Testdaten: \\t\\t\" + str(len(y_test)) + \" / \" + str(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Daten vorbereiten - Normierung der Daten\n",
    "__Optional__ können die Input-Parameter normiert werden.   \n",
    "Allerdings hat dies keine Auswirkungen auf die Performance der Entscheidungsbaum-basierten Verfahren. \n",
    "Daher wird hier auf diesen Schritt verzichtet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modell bilden - Modell importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere das Modell aus der Bibliothek sklearn\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modelle bilden - Hyperparameter Tuning mittels Gittersuche\n",
    "\n",
    "Um die optimalen Werte für die Hyperparameter zu finden, wird eine Gittersuche mit Crossvalidation __GridSearchCV__ durchgeführt:\n",
    "1. Hyperparameter bestimmen\\\n",
    "Für die Ensemble Learning Verfahren RandomForest und GradientBoosting werden in diesem Notebook 3 Hyperparameter eingestellt:\n",
    "- n_estimators: Anzahl der Bäume, Suchbereich Liste [50, 100, 150, 200]\n",
    "- contamination: Anteil der Ausreißer die im Datensatz angenommen werden, Suchbereich Liste [0.01, 0.03, 0.05, 0.07]\n",
    "- max_features: Maximale Anzahl Features je Baum, Suchbereich\\\n",
    "Die Hyperparameter werden als Dictionary gebraucht, das ist eine Datenstruktur mit mehreren Einträgen von key-Value Paaren, d.h. eindeutige Bezeichner (keys) und den zugehörigen Werten.\n",
    "\n",
    "\n",
    "2. Modell erstellen\\\n",
    "Wenn manche Hyperparameter nur einen Wert annehmen sollen, so kann man diese entweder als Hyperparameter in Schritt 1 mit aufnehmen oder direkt an das Modell übergeben. \n",
    "\n",
    "3. Gittersuche parameterieren\\\n",
    "In diesem Schritt werden Parameter für die Klasse GridSearchCV eingestellt und dann in einer Variable gespeichert.\\\n",
    "Parameter: \n",
    "* 1. Parameter: das ML-Modell, hier model \n",
    "* 2. Parameter: die Hyperparameter, hier hyper_parameters, diese müssen als dictionary gegeben sein (vgl. Schritt 1) \n",
    "* return_train_score=True, um die Trainingsergebnisse zu erhalten\n",
    "* cv=5, Anzahl der Folds, die gebildet werden \n",
    "* n_jobs=-2 Parallelisierung der Berechnung, alle bis auf ein Prozessorkern wird genutzt\n",
    "\n",
    "4. Modelle trainieren\\\n",
    "Das Training der Modelle erfolgt wieder mit dem fit Befehl. Diesem müssen die Trainingsdaten übergeben werden. \n",
    "\n",
    "TODO:\n",
    "- Erzeuge ein Modell, Random Forest oder Gradien Boosting Model, je nach Wunsch\n",
    "- Übergebe der GridSearchCV Klasse, das Modell (model) und die Hyperparameter (hyper_parameters)\n",
    "- Setze die Trainingsdaten in den .fit-Befehle ein (X_train und y_train)  \n",
    "    \n",
    "AUSGABE:\n",
    "- Anzahl der getesteten Hyperparameterkombinationen\n",
    "- Zeitdauer für Gittersuche\n",
    "- bestes Modell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung und Training der Modelle \n",
    "\n",
    "# Werte für die Gittersuche/Hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "start_timer = time.monotonic()\n",
    "# 1. Hyperparameter bestimmen - für die Suche und Suchbereiche \n",
    "hyper_parameters = {\"n_estimators\": [50, 100, 150, 200], \n",
    "                    \"contamination\":  [0.03, 0.04, 0.05, 0.06, 0.07], \n",
    "                    \"max_features\" : [0.7, 0.8, 0.9, 1]}\n",
    "\n",
    "# 2. Modell erzeugen\n",
    "model = IsolationForest(random_state=my_seed)\n",
    "\n",
    "# Achtung GridSearch will Modelle, die eine Scoring Funktion besitzen. \n",
    "# Da der IsolationForest keine besitzt, wird eine Scoring Function (Accuracy) definiert\n",
    "def scorer_f(estimator, X, y): \n",
    "      return accuracy_score(estimator.predict(X),y)\n",
    "\n",
    "# 3. Gittersuche parametrieren\n",
    "gridSearch = GridSearchCV(model, hyper_parameters, return_train_score=True, cv=5, n_jobs=-2, scoring=scorer_f)\n",
    "\n",
    "# 4. Modelle trainieren\n",
    "gridSearch = gridSearch.fit(X_train.values, y_train)\n",
    "print(\"\\nDie Gittersuche (\" + str(len(pd.DataFrame(gridSearch.cv_results_)))\n",
    "      + \" Kombinationen) hat \" + str(\"%.1f\" % (time.monotonic() - start_timer))\n",
    "      + \" Sekunden gedauert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Modelle validieren - GridSearch Ergebnisse begutachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Variablen GridSearch sind nun die Ergebnisse der Gittersuche gespeichert.  \n",
    "\n",
    "Mit dem Befahl GridSearch.cv_results_ bekommen wir die Ergebnis-Tabelle der Gittersuche (hier: besten 5 Ergebnisse):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Ergebnisse\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.DataFrame(gridSearch.cv_results_).sort_values(\"mean_test_score\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Modelle validieren - Modell auswählen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem Befehl GridSearch.best_params_ bekommen wir die besten Hyperparameter der Gittersuche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beste Kombination der Hyperparameter\n",
    "gridSearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun muss das Modell mit den optimalen Hyperparametern erstellt und dann mit den Trainingsdaten trainiert werden.  \n",
    "Diese Aufgabe übernimmt bereits die GridSearch-Funktion. Somit muss das beste Modell nur noch extrahiert werden, das geht mit dem Befehl GridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraktion des Modells\n",
    "model = gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Modelle validieren - Bewertung des Trainings\n",
    "Wir berechnen die Genauigkeit des Modells auf den Trainingsdaten (richtige Vorhersagen/alle Vorhersagen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Vorhersage basierend auf den Trainingsdaten\n",
    "y_train_pred = model.predict(X_train.values)\n",
    "\n",
    "# Berechne Genauigkeit auf den Trainingsdaten\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Berechne den F1-Score auf den Trainingsdaten\n",
    "f1score_train = f1_score(y_train, y_train_pred)\n",
    "\n",
    "# Ausgabe der Modellgenauigkeit\n",
    "print('Ergebnis für das Training:')\n",
    "print('Accuracy: \\t' + str(round(accuracy_train, 4)))\n",
    "print('F1-Score: \\t' + str(round(f1score_train, 4)))\n",
    "\n",
    "# Visualisierung der Konfusionsmatrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)\n",
    "plt.grid()\n",
    "plt.title('Konfusionsmatrix auf Trainingsdaten')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Modell testen & anwenden - Genauigkeit auf Testdaten und Konfusionsmatrix\n",
    "\n",
    "Um die Qualität/Güte des Modells zu bestimmen wird dieses auf den Testdaten getestet und die Konfusionsmatrix ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Vorhersage basierend auf den Testdaten\n",
    "y_test_pred = model.predict(X_test.values)\n",
    "\n",
    "# Berechne Genauigkeit auf den Testdaten\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Berechne den F1-Score auf den Testdaten\n",
    "f1score_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Ausgabe der Modellgenauigkeit\n",
    "print('Ergebnis für den Test:')\n",
    "print('Accuracy: \\t' + str(round(accuracy_test, 4)))\n",
    "print('F1-Score: \\t' + str(round(f1score_test, 4)))\n",
    "\n",
    "# Visualisierung der Konfusionsmatrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)\n",
    "plt.grid()\n",
    "plt.title('Konfusionsmatrix auf Testdaten')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MLiP)",
   "language": "python",
   "name": "python-mlip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
